I imagine chunking text will still be useful for things like retrieval augmented generation, where lots of information is split into small chunks, so that only the most relevant chunk/s are passed as part of a prompt to help answer a question asked of an LLM about custom data.

In my mind, smaller chunks of specific information will be more valuable than passing in a lot of data and expecting the LLM to identify the most relevant from a wall of text, similar to how a human might feel overwhelmed by information overload. Though maybe a computer would handle that better?