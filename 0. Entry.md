
## Todos

- Add note to explain why incremental updating addresses a problem with hierarchical merging.
- Try out both strategies on a single book.


## Questions to explore

- Why are generated book summaries better than human summaries? (see [[2. Generated book summaries are better than human summaries]])
- will chunking still be necessary for bigger context windows? (see [[3a. Will chunking still be necessary for bigger context windows?]])
- Is chunking useful for preventing info overload in rag? (see [[3a1. Chunking helps prevent info overload in RAG]])
- What if a [[4. What if a book summary exists in LLM training data?|book summary already exists as part of the training data for LLMs]]?