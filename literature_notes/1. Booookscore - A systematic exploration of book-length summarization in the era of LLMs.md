#litnote

Workspace notes

- Three challenges with evaluating the capabilities of LLMs on book-length summarisation:
	- Problem: Data contamination where book summaries have already been used as part of the training data for LLMs, like BookSum which contains many book summaries.
	- Limited research on coherence errors made worse by the chunk and combine book-length summarisations.
	- Lack of reliable automatic metrics that have been validated against human annotations (assumes that human annotations will be validating.)

- Protocol for evaluating coherence in book-length summarisation, which leverages human annotation of the coherence (logical connectedness) of LLM-generated summaries. The protocol unifies and extends best-practices across works in document understanding and evaluation research.
	- Best practices:
		- fine-grained annotation units (Krishna et al, 2023)
		- QA pairs to denote points of confusion (Ko et al, 2020)
		- Taxonomic breakdown of different coherence errors (Goyal et all, 2022a)
	- How effectiveness of this protocol is measured:
		- Collecting 1193 span-level human annotations on GPT-4 generated summaries of a set of 100 recently-published books (costing $3k and 100 annotator hours).
		- Each annotation was categorised into 8 different error types, 2 of which did not show up in studies on shorter document summarisers (causal omissions, salience errors).
			- Q. What about the other LLMs.
		- Summaries created using two prompting strategies:
			- Hierarchical merging
			- Incremental updating
	- Mitigates the impact of data contamination by designing the evaluation framework around newly published books.
		- That doesn't mitigate it, it avoids it by referencing books that the model can't possibly know about, and relies on LLMs being slow to update their training data.
	- Definition: Coherence means logical connectedness.

Coherence errors:

- Entity omission: A person, object or place etc is mentioned in the summary, but key context or details are missing or unclear.
- Event omission: An event is mentioned in the summary, but key details are missing or unclear.
- Causal omission: A reason or motivation is missing or under explained.
- Discontinuity: An interruption in the flow of the narrative such as sudden jumps in time or perspective.
- Salience: Inclusion of details that do not contribute to the main plot.
- Language: Spelling or grammar issues; ambiguous wording.
- Inconcistency: A discrepancy or contradiction within a story's plot, character development or themes.
- Duplication: Redundant repetition of similar information.


Q. What are each of the 8 different error types, what do they mean and how are they caused?

Q. Define coherence - Logical connectedness.
Q. Define human annotations.
Q. Define span-level human annotations.
Q. Define protocol.
Q. Define eschew.
Q. Define gold reference summaries.
Q. Define disparate.

---





Keepsies

Purpose: How to generate a book summary that is as good or better than a human can do.


- Evidence: Pu et al found in 2023 that summaries generated by LLMs are preferred over those written by humans (Xiao Pu, Mingqi Gao, and Xiaojun Wan. Summarization is (almost) dead, 2023b.)
	- Read this paper because that's a critical point and I want to know the reasons why they were preferred by those written by humans.

- Definition: Book-length documents are texts that are longer than 100k tokens (pp.1).
- Issue: Book-length documents (100k and larger) exceed the context window limits of today's LLMs (8k tokens for GPT-3.5 and GPT-4).
	- Consequently, we need to split the text into smaller pieces that fit within the context window (chunking), then process each chunk (summarise them), then combine and compress each chunk to create a summary of the whole book.
	- (Wu et al, 2021: Jeff Wu, Long Ouyang, Daniel M. Ziegler, Nisan Stiennon, Ryan Lowe, Jan Leike, and Paul Chris- tiano. Recursively summarizing books with human feedback, 2021.)
		- Q.What happens when the context window expands? Yesterday for example (Nov 6 2023), OpenAI released a statement that they were going to increase the context window from 8k to 120k tokens, which would cover most book-length documents. Claude is already close to that.
	- Problem: Data contamination where book summaries have already been used as part of the training data for LLMs, like BookSum which contains many book summaries.

---
Chang, Y., Lo, K., Goyal, T., & Iyyer, M. (2023). BooookScore: A systematic exploration of book-length summarization in the era of LLMs. arXiv:2310.00785 [cs.CL]. [https://doi.org/10.48550/arXiv.2310.00785](https://doi.org/10.48550/arXiv.2310.00785)